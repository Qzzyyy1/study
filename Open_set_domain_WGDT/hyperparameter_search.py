"""
è¶…å‚æ•°æœç´¢è„šæœ¬ - å¯»æ‰¾æœ€ä¼˜çš„ä¼ªæ ‡ç­¾å‚æ•°
æ”¯æŒç½‘æ ¼æœç´¢å’Œéšæœºæœç´¢ä¸¤ç§æ¨¡å¼
"""

import os
import json
import subprocess
import argparse
import re
from datetime import datetime
from itertools import product
import numpy as np

class HyperparameterSearch:
    def __init__(self, base_args, search_mode='grid'):
        self.base_args = base_args
        self.search_mode = search_mode
        self.results = []
        self.log_file = f'hyperparam_search_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        # åˆ›å»ºä¸€ä¸ªæ€»çš„ debug æ—¥å¿—ï¼Œè€Œä¸æ˜¯æ¯ä¸ª trial å»ºä¸€ä¸ªæ–°æ–‡ä»¶
        self.debug_file = f'output_debug_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        
    def grid_search(self, param_grid):
        """ç½‘æ ¼æœç´¢ï¼šéå†æ‰€æœ‰å‚æ•°ç»„åˆ"""
        print("=" * 60)
        print("å¼€å§‹ç½‘æ ¼æœç´¢ (Grid Search)")
        print("=" * 60)
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        keys = list(param_grid.keys())
        values = list(param_grid.values())
        combinations = list(product(*values))
        
        total = len(combinations)
        print(f"æ€»å…±éœ€è¦æµ‹è¯• {total} ç»„å‚æ•°\n")
        
        for idx, combo in enumerate(combinations, 1):
            params = dict(zip(keys, combo))
            print(f"\n[{idx}/{total}] æµ‹è¯•å‚æ•°ç»„åˆ:")
            for k, v in params.items():
                print(f"  {k}: {v}")
            
            result = self.run_experiment(params, idx)
            self.results.append(result)
            self.save_results()
            
        return self.get_best_result()
    
    def random_search(self, param_ranges, n_trials=20):
        """éšæœºæœç´¢ï¼šéšæœºé‡‡æ ·å‚æ•°ç»„åˆ"""
        print("=" * 60)
        print(f"å¼€å§‹éšæœºæœç´¢ (Random Search) - {n_trials} æ¬¡è¯•éªŒ")
        print("=" * 60)
        
        for idx in range(1, n_trials + 1):
            # éšæœºé‡‡æ ·å‚æ•°
            params = {}
            for key, (low, high) in param_ranges.items():
                if isinstance(low, float):
                    params[key] = np.random.uniform(low, high)
                else:
                    params[key] = np.random.randint(low, high + 1)
            
            print(f"\n[{idx}/{n_trials}] æµ‹è¯•å‚æ•°ç»„åˆ:")
            for k, v in params.items():
                print(f"  {k}: {v}")
            
            result = self.run_experiment(params, idx)
            self.results.append(result)
            self.save_results()
            
        return self.get_best_result()
    
    def run_experiment(self, params, trial_id):
        """è¿è¡Œå•æ¬¡å®éªŒ"""
        # æ„å»ºå‘½ä»¤
        cmd = ['python', 'main.py']
        
        # æ·»åŠ åŸºç¡€å‚æ•°
        for key, value in self.base_args.items():
            cmd.extend([f'--{key}', str(value)])
        
        # æ·»åŠ æœç´¢å‚æ•°
        for key, value in params.items():
            cmd.extend([f'--{key}', str(value)])
        
        print(f"\næ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print("-" * 60)
        
        try:
            # è¿è¡Œå®éªŒ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            # è§£æç»“æœ
            metrics = self.parse_output(result.stdout, trial_id)
            
            experiment_result = {
                'trial_id': trial_id,
                'params': params,
                'metrics': metrics,
                'status': 'success' if result.returncode == 0 else 'failed',
                'timestamp': datetime.now().isoformat()
            }
            
            print("\nç»“æœ:")
            if metrics:
                for k, v in metrics.items():
                    print(f"  {k}: {v:.4f}")
            else:
                print("  æœªèƒ½è§£æåˆ°ç»“æœæŒ‡æ ‡")
                if result.returncode != 0:
                    print(f"  é”™è¯¯ä¿¡æ¯æ‘˜è¦: {result.stderr[:200]}...")
            
            return experiment_result
            
        except subprocess.TimeoutExpired:
            print("å®éªŒè¶…æ—¶ï¼")
            return {
                'trial_id': trial_id,
                'params': params,
                'metrics': {},
                'status': 'timeout',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"å®éªŒå¤±è´¥: {str(e)}")
            return {
                'trial_id': trial_id,
                'params': params,
                'metrics': {},
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def parse_output(self, output, trial_id):
        """ä»è¾“å‡ºä¸­è§£ææ€§èƒ½æŒ‡æ ‡ - å¢å¼ºç‰ˆ"""
        metrics = {}
        
        # å°†å®Œæ•´è¾“å‡ºè¿½åŠ åˆ°æ€»çš„ debug æ–‡ä»¶ä¸­ï¼Œè€Œä¸æ˜¯æ¯æ¬¡æ–°å»ºæ–‡ä»¶
        with open(self.debug_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*20} Trial {trial_id} {'='*20}\n")
            f.write(output)
            f.write("\n")
        
        lines = output.split('\n')
        
        # æ¨¡å¼1: æŸ¥æ‰¾ "æŒ‡æ ‡å: æ•°å€¼" æ ¼å¼ (å°†æ­£åˆ™å’ŒæŒ‡æ ‡åç§°ç»‘å®š)
        patterns = [
            ('OS*', r'OS\*[:\s]+([0-9.]+)'),
            ('OS', r'OS[:\s]+([0-9.]+)'),
            ('H-score', r'H-score[:\s]+([0-9.]+)'),
            ('h-score', r'h-score[:\s]+([0-9.]+)'),
            ('accuracy', r'accuracy[:\s]+([0-9.]+)'),
            ('Accuracy', r'Accuracy[:\s]+([0-9.]+)'),
            ('known_acc', r'known[_\s]acc[:\s]+([0-9.]+)'),
            ('unknown_acc', r'unknown[_\s]acc[:\s]+([0-9.]+)'),
            ('target_acc', r'target[_\s]acc[:\s]+([0-9.]+)'),
        ]
        
        for line in lines:
            for metric_name, pattern in patterns:
                match = re.search(pattern, line, re.IGNORECASE)
                if match:
                    metrics[metric_name] = float(match.group(1))
        
        # æ¨¡å¼2: æŸ¥æ‰¾è¡¨æ ¼æ ¼å¼çš„è¾“å‡º
        # ä¾‹å¦‚: | OS* | 0.8523 |
        for line in lines:
            if '|' in line:
                parts = [p.strip() for p in line.split('|') if p.strip()]
                if len(parts) >= 2:
                    try:
                        metric_name = parts[0]
                        metric_value = float(parts[1])
                        metrics[metric_name] = metric_value
                    except ValueError:
                        pass
        
        # æ¨¡å¼3: æŸ¥æ‰¾æœ€åå‡ è¡Œçš„æ•°å­—ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç»“æœï¼‰
        last_lines = lines[-20:]  # æ£€æŸ¥æœ€å20è¡Œ
        for line in last_lines:
            # æŸ¥æ‰¾æ‰€æœ‰æµ®ç‚¹æ•°
            numbers = re.findall(r'\b([0-9]+\.[0-9]+)\b', line)
            if numbers and any(keyword in line.lower() for keyword in ['test', 'final', 'result', 'performance']):
                for num in numbers:
                    value = float(num)
                    if 0 < value <= 1:  # å‡è®¾æŒ‡æ ‡åœ¨0-1ä¹‹é—´
                        if 'final_score' not in metrics:
                            metrics['final_score'] = value
        
        return metrics
    
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump({
                'search_mode': self.search_mode,
                'base_args': self.base_args,
                'results': self.results,
                'best_result': self.get_best_result() if self.results else None
            }, f, indent=2, ensure_ascii=False)
        # ä¸å†æ¯æ¬¡æ‰“å°ä¿å­˜è·¯å¾„ï¼Œä¿æŒæ§åˆ¶å°æ•´æ´
    
    def get_best_result(self):
        """è·å–æœ€ä½³ç»“æœ"""
        if not self.results:
            return None
        
        # è¿‡æ»¤æˆåŠŸçš„å®éªŒ
        successful = [r for r in self.results if r['status'] == 'success' and r['metrics']]
        
        if not successful:
            return None
        
        # æ ¹æ®ä¸»è¦æŒ‡æ ‡æ’åºï¼ˆä¼˜å…ˆä½¿ç”¨OS*ï¼Œå…¶æ¬¡OSï¼Œæœ€åaccuracyï¼‰
        def get_score(result):
            metrics = result['metrics']
            if 'OS*' in metrics:
                return metrics['OS*']
            elif 'OS' in metrics:
                return metrics['OS']
            elif 'accuracy' in metrics:
                return metrics['accuracy']
            elif 'H-score' in metrics:
                return metrics['H-score']
            elif 'h-score' in metrics:
                return metrics['h-score']
            else:
                return 0.0
        
        best = max(successful, key=get_score)
        return best
    
    def print_summary(self):
        """æ‰“å°æœç´¢æ€»ç»“"""
        print("\n" + "=" * 60)
        print("è¶…å‚æ•°æœç´¢å®Œæˆï¼")
        print("=" * 60)
        
        if not self.results:
            print("æ²¡æœ‰å®Œæˆä»»ä½•å®éªŒ")
            return
        
        successful = [r for r in self.results if r['status'] == 'success' and r['metrics']]
        print(f"\næ€»å®éªŒæ¬¡æ•°: {len(self.results)}")
        print(f"æˆåŠŸæ¬¡æ•°: {len(successful)}")
        print(f"å¤±è´¥æ¬¡æ•°: {len(self.results) - len(successful)}")
        
        best = self.get_best_result()
        if best:
            print("\n" + "ğŸ† æœ€ä½³å‚æ•°ç»„åˆ:")
            print("-" * 60)
            # ä¿®å¤äº†è¿™é‡Œçš„è§£åŒ…é”™è¯¯
            for k, v in best['params'].items():
                print(f"  {k}: {v}")
            print("\næ€§èƒ½æŒ‡æ ‡:")
            # ä¿®å¤äº†è¿™é‡Œçš„è§£åŒ…é”™è¯¯
            for k, v in best['metrics'].items():
                print(f"  {k}: {v:.4f}")
        else:
            print("\næœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³ç»“æœ")
        
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {self.log_file}")
        print(f"æ§åˆ¶å°è¾“å‡ºæ—¥å¿—ä¿å­˜åœ¨: {self.debug_file}")


def main():
    parser = argparse.ArgumentParser(description='WGDTè¶…å‚æ•°æœç´¢')
    
    # æœç´¢æ¨¡å¼
    parser.add_argument('--search_mode', type=str, choices=['grid', 'random'], default='grid',
                        help='æœç´¢æ¨¡å¼: grid(ç½‘æ ¼æœç´¢) æˆ– random(éšæœºæœç´¢)')
    parser.add_argument('--n_trials', type=int, default=20,
                        help='éšæœºæœç´¢çš„è¯•éªŒæ¬¡æ•°')
    
    # åŸºç¡€å‚æ•°ï¼ˆä¸å‚ä¸æœç´¢ï¼‰
    parser.add_argument('--source_dataset', type=str, default='Houston13_7gt')
    parser.add_argument('--target_dataset', type=str, default='Houston18_OS')
    parser.add_argument('--device', type=int, default=0)
    parser.add_argument('--epoch', type=int, default=150)
    parser.add_argument('--seed', type=int, default=0)
    
    args = parser.parse_args()
    
    # åŸºç¡€å‚æ•°
    base_args = {
        'source_dataset': args.source_dataset,
        'target_dataset': args.target_dataset,
        'device': args.device,
        'epochs': args.epochs,
        'seed': args.seed,
    }
    
    # åˆ›å»ºæœç´¢å™¨
    searcher = HyperparameterSearch(base_args, search_mode=args.search_mode)
    
    if args.search_mode == 'grid':
        # ç½‘æ ¼æœç´¢çš„å‚æ•°ç©ºé—´
        param_grid = {
            'pseudo_label_weight': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            'pseudo_label_threshold': [0.1, 0.2, 0.3, 0.4, 0.5],
            "radius_init": [0.1, 0.2, 0.3, 0.4, 0.5],
            "radius_margin": [0.01, 0.05, 0.10, 0.15, 0.20, 0.3, 0.4]
        }
        
        print("ç½‘æ ¼æœç´¢å‚æ•°ç©ºé—´:")
        # ä¿®å¤äº†è¿™é‡Œçš„è§£åŒ…é”™è¯¯
        for k, v in param_grid.items():
            print(f"  {k}: {v}")
        
        best = searcher.grid_search(param_grid)
        
    else:  # random search
        # éšæœºæœç´¢çš„å‚æ•°èŒƒå›´
        param_ranges = {
            'pseudo_label_weight': (0.1, 1.0),      # [0.1, 1.0]
            'pseudo_label_threshold': (0.1, 0.6)    # [0.1, 0.6]
        }
        
        print("éšæœºæœç´¢å‚æ•°èŒƒå›´:")
        for k, v in param_ranges.items():
            print(f"  {k}: {v}")
        
        best = searcher.random_search(param_ranges, n_trials=args.n_trials)
    
    # æ‰“å°æ€»ç»“
    searcher.print_summary()


if __name__ == '__main__':
    main()